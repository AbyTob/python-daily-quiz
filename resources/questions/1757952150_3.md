# Python Quiz Question
    
    ## Question
    Part 1 (Question):
You are tasked with creating a Python script that utilizes asyncio and coroutines to simulate a scenario where multiple tasks run concurrently, each fetching data from an API. The goal is to understand how to manage asynchronous tasks efficiently.

Write a function `fetch_data(url)` that uses the `aiohttp` library to fetch data from a given URL asynchronously. Then, create another function `run_tasks(urls)` that takes a list of URLs and runs them concurrently using asyncio, returning a list of fetched data in the order of the input list.

Ensure that your code handles exceptions gracefully by catching any errors that occur during the fetching process and continuing with the next task.

Here's an example to get you started:
```python
import aiohttp
import asyncio

# Define the function fetch_data(url) here
# Use aiohttp.ClientSession() to create a session and make async requests

# Define the function run_tasks(urls) here
# Use asyncio.gather() to run tasks concurrently and wait for all of them to complete

# Example usage:
urls = [
    'https://api.example.com/data1',
    'https://api.example.com/data2',
    'https://api.example.com/data3'
]
results = asyncio.run(run_tasks(urls))
print(results)
```
    
    ## Answer
    Part 2 (Answer):
The correct answer is not provided directly, as the task requires coding and running a solution. Here's an example of how you might implement the functions:

```python
import aiohttp
import asyncio

async def fetch_data(url):
    async with aiohttp.ClientSession() as session:
        try:
            async with session.get(url) as response:
                return await response.json()
        except Exception as e:
            print(f"Error fetching {url}: {e}")
            return None

async def run_tasks(urls):
    tasks = [fetch_data(url) for url in urls]
    results = await asyncio.gather(*tasks)
    return [result for result in results if result is not None]

# Example usage:
urls = [
    'https://api.example.com/data1',
    'https://api.example.com/data2',
    'https://api.example.com/data3'
]
results = asyncio.run(run_tasks(urls))
print(results)
```

In this solution, `fetch_data` is an asynchronous function that fetches data from a given URL using `aiohttp.ClientSession()`. The `run_tasks` function creates a list of tasks to be run concurrently and uses `asyncio.gather()` to wait for all of them to complete. It also handles exceptions by catching errors during the fetching process and skipping the task if an error occurs.

The example usage demonstrates how to run the `run_tasks` function with a list of URLs, waiting for the results using `asyncio.run()`. The results are printed, showing the fetched data in the order of the input list.
    
    ---
    *Generated on: 2025-09-15 16:02:30*
    