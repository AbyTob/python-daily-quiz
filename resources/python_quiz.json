{
  "q1_2025-04-23": {
    "question": "**Question**\n\nYou are tasked with implementing a logging system that utilizes context managers for managing loggers. The logging system should have the following properties:\n- It should be thread-safe.\n- It should support logging at different levels (debug, info, warning, error).\n- It should automatically close the logger when the program exits.\n\nHere's an example of how you might start implementing it:\n\n```python\nimport threading\n\nclass Logger:\n    def __init__(self):\n        self.logger = {}\n        self.lock = threading.Lock()\n\n    # Add a context manager to manage loggers\n    class LogContextManager:\n        def __enter__(self, name):\n            with self.lock:\n                if name not in self.logger:\n                    self.logger[name] = []\n\n        def __exit__(self, exc_type, exc_val, exc_tb):\n            pass\n\n# Usage:\nlogger = Logger()\n\nwith logger.LogContextManager('my_logger'):\n    print(logger.logger['my_logger'])\n```\n\nHowever, this basic implementation is still quite far from a full-fledged logging system. We need to add support for different log levels and implement the `__exit__` method correctly.\n\n**Options**\n\nA) Define a `LogLevel` enum with values like `DEBUG`, `INFO`, `WARNING`, and `ERROR`. Then, modify the `Logger` class to take an optional `level` parameter in its constructor. Implement the `__exit__` method to filter log messages based on the specified level.\n\nB) Use the `contextlib` module's `contextmanager` decorator to define a context manager for logging. This would require modifying the `LogContextManager` class significantly.\n\nC) Create a separate class, `LoggerThreadSafe`, that inherits from the `threading.Thread` class and overrides its `run` method. In this implementation, we'll create a logger instance within the thread's `run` method and use a shared logger across all threads.\n\nD) Use Python's built-in `multiprocessing` module to manage loggers across multiple processes. This approach would require creating separate logger instances for each process.\n\n**ANSWER_SEPARATOR**\n\n[ANSWER]\n\n**Answer**\n\nThe correct answer is A) Define a `LogLevel` enum with values like `DEBUG`, `INFO`, `WARNING`, and `ERROR`. Then, modify the `Logger` class to take an optional `level` parameter in its constructor. Implement the `__exit__` method to filter log messages based on the specified level.\n\nHere's an example implementation of how you can modify the `Logger` class:\n\n```python\nimport threading\n\nclass LogLevel:\n    DEBUG = 1\n    INFO = 2\n    WARNING = 3\n    ERROR = 4\n\nclass Logger:\n    def __init__(self, level=LogLevel.INFO):\n        self.logger = {}\n        self.lock = threading.Lock()\n        self.level = level\n\n    # Add a context manager to manage loggers\n    class LogContextManager:\n        def __enter__(self, name):\n            with self.lock:\n                if name not in self.logger:\n                    self.logger[name] = []\n\n        def __exit__(self, exc_type, exc_val, exc_tb):\n            pass\n\n    # Modify the context manager to filter log messages\n    @classmethod\n    def log_context_manager(cls, name, level=LogLevel.INFO):\n        return cls.LogContextManager(name)\n\n    # Define a logging function with filtering based on level\n    def _log(self, message, level):\n        if level <= self.level:\n            print(f\"[{self._get_level_name(level)}] {message}\")\n\n    def _get_level_name(self, level):\n        levels = {\n            LogLevel.DEBUG: \"DEBUG\",\n            LogLevel.INFO: \"INFO\",\n            LogLevel.WARNING: \"WARNING\",\n            LogLevel.ERROR: \"ERROR\"\n        }\n        return levels.get(level)\n\n# Usage:\nlogger = Logger(LogLevel.ERROR)\nwith logger.log_context_manager('my_logger'):\n    logger._log(\"This is an error message\", LogLevel.ERROR)\n```\n\nIn this implementation, we've modified the `Logger` class to take a `level` parameter in its constructor. We've also added a `LogContextManager` class that filters log messages based on the specified level when used as a context manager.\n\nThe `_log` method is a private helper function that logs a message with filtering based on the specified level. The `_get_level_name` function returns the corresponding name for a given log level.\n\nThis implementation provides a basic logging system that meets all the requirements mentioned in the question, including thread-safety and automatic logger closure when the program exits.",
    "answer": "Answer format error. Please check the generated content.",
    "timestamp": "2025-04-23 18:50:44"
  },
  "q1_2025-04-25": {
    "question": "[QUESTION]\nConsider the following Python code that uses a metaclass to enforce certain rules on class attributes. The goal is to ensure that all string attributes in any subclass of `BaseClass` must be non-empty.\n\n```python\nclass Meta(type):\n    def __new__(cls, name, bases, dct):\n        for attr_name, value in dct.items():\n            if isinstance(value, str) and not value:\n                raise ValueError(f\"String attribute '{attr_name}' cannot be empty\")\n        return super().__new__(cls, name, bases, dct)\n\nclass BaseClass(metaclass=Meta):\n    def __init_subclass__(cls):\n        for attr_name in cls.__dict__:\n            value = getattr(cls, attr_name)\n            if isinstance(value, str) and not value:\n                raise ValueError(f\"String attribute '{attr_name}' cannot be empty\")\n\nclass DerivedClass(BaseClass):\n    non_empty_attr = \"Value\"\n    empty_attr = \"\"  # This should trigger a validation error\n```\n\nWhat will happen when you try to define the `DerivedClass`?\n\nA) The class will be defined successfully, and an instance of `DerivedClass` can be created.\nB) A `ValueError` will be raised because `empty_attr` is an empty string.\nC) The metaclass will not allow `DerivedClass` to be defined at all.\nD) An `AttributeError` will be raised when trying to access `empty_attr`.",
    "answer": "B) A `ValueError` will be raised because `empty_attr` is an empty string.\n\nExplanation: In the provided code, the metaclass `Meta` checks for any string attributes that are empty during the class creation. Since `DerivedClass` has an attribute `empty_attr` which is an empty string, the metaclass raises a `ValueError`. The `__init_subclass__` method in `BaseClass` does not add additional validation logic beyond what the metaclass already enforces, so it does not change this behavior.",
    "timestamp": "2025-04-25 21:50:44"
  },
  "q2_2025-04-25": {
    "question": "[QUESTION]\nYou are tasked with creating a decorator that measures the execution time of any function it decorates. However, this decorator should also handle nested decorators without interfering with their timing calculations. Implement such a decorator in Python.\n\nHere's a code snippet to get you started:\n\n```python\nimport time\n\ndef timer(func):\n    def wrapper(*args, **kwargs):\n        start_time = time.time()\n        result = func(*args, **kwargs)\n        end_time = time.time()\n        print(f\"Function {func.__name__} took {end_time - start_time:.4f} seconds to execute.\")\n        return result\n    return wrapper\n\n@timer\ndef nested_function():\n    time.sleep(1)\n    @timer\n    def inner_function():\n        time.sleep(0.5)\n\nnested_function()\n```\n\nWhat modifications are needed in the `timer` decorator to ensure that it correctly handles nested decorators and accurately measures their execution times?\n\nA) No changes are needed.\nB) Use a class-based approach with an `__call__` method.\nC) Add a unique identifier for each decorated function to avoid overwriting timers.\nD) Modify the decorator to use a global dictionary to store start and end times.",
    "answer": "[ANSWER]\nA) No changes are needed.\n\nExplanation: The provided code snippet already correctly implements a decorator that measures the execution time of any function it decorates, including nested decorators. Each call to `wrapper` captures the start and end times for its own scope and prints the duration, which is then passed on to the original function call. There's no need for additional changes such as using a class-based approach, adding unique identifiers, or using a global dictionary for managing start and end times. The existing implementation handles nested decorators seamlessly by creating separate timers for each level of nesting.",
    "timestamp": "2025-04-25 21:57:00"
  },
  "q1_2025-04-26": {
    "question": "[QUESTION]\nConsider the following Python code snippet that uses a decorator to modify the behavior of class methods:\n\n```python\ndef log_method_calls(cls):\n    for name, method in cls.__dict__.items():\n        if callable(method) and not name.startswith('__'):\n            setattr(cls, name, _log_call(method))\n    return cls\n\ndef _log_call(func):\n    def wrapper(*args, **kwargs):\n        print(f\"Calling {func.__name__} with args: {args}, kwargs: {kwargs}\")\n        result = func(*args, **kwargs)\n        print(f\"{func.__name__} returned: {result}\")\n        return result\n    return wrapper\n\n@log_method_calls\nclass MyClass:\n    def method1(self, x):\n        return x * 2\n    \n    def method2(self, y):\n        return y + 3\n```\n\nWhich of the following statements about this code is correct?\n\nA) The `log_method_calls` decorator does not modify the behavior of instance methods.\n\nB) When an instance of `MyClass` calls `method1(5)`, it will print: \"Calling method1 with args: (5,), kwargs: {}\" followed by \"method1 returned: 10\".\n\nC) The `_log_call` function will only log calls to class methods that start with 'method'.\n\nD) All instance methods of `MyClass` are now synchronous and cannot be used in an asynchronous context.",
    "answer": "B) When an instance of `MyClass` calls `method1(5)`, it will print: \"Calling method1 with args: (5,), kwargs: {}\" followed by \"method1 returned: 10\".\n\nExplanation:\nThe `log_method_calls` decorator iterates over all attributes of the class and applies the `_log_call` wrapper to any callable attribute that is not a special method. In this case, both `method1` and `method2` are instance methods, so they are wrapped by `_log_call`. When an instance of `MyClass` calls `method1(5)`, it indeed prints the method call with arguments and returns the result as specified.",
    "timestamp": "2025-04-26 11:33:34"
  },
  "q2_2025-04-26": {
    "question": "**Part 1 (Question):**\n\nConsider the following Python code:\n\n```python\nimport asyncio\n\nclass AsyncTimer:\n    def __init__(self, interval):\n        self.interval = interval\n        self.running = False\n\n    async def start(self):\n        while self.running:\n            await asyncio.sleep(self.interval)\n            print(f\"Timer ticked at {self.interval} seconds\")\n\ndef async_timer_decorator(func):\n    async def wrapper(*args, **kwargs):\n        timer = AsyncTimer(1)  # Timer set to tick every second\n        timer.running = True\n        task = asyncio.create_task(timer.start())\n        result = await func(*args, **kwargs)\n        timer.running = False\n        return result\n    return wrapper\n\n@async_timer_decorator\nasync def long_running_task():\n    print(\"Starting long running task\")\n    for i in range(5):\n        await asyncio.sleep(1)  # Simulate work with sleep\n        print(f\"Task progress: {i+1}/5\")\n    print(\"Long running task completed\")\n\n# Run the async task\nasyncio.run(long_running_task())\n```\n\nWhat will be printed when you run this code?\n\nA. Starting long running task  \n   Timer ticked at 1 seconds  \n   Task progress: 1/5  \n   Task progress: 2/5  \n   Task progress: 3/5  \n   Task progress: 4/5  \n   Long running task completed  \n\nB. Starting long running task  \n   Long running task completed  \n   Timer ticked at 1 seconds  \n   Task progress: 1/5  \n   Task progress: 2/5  \n   Task progress: 3/5  \n   Task progress: 4/5  \n\nC. Starting long running task  \n   Timer ticked at 1 seconds  \n   Task progress: 1/5  \n   Long running task completed  \n   Task progress: 2/5  \n   Task progress: 3/5  \n   Task progress: 4/5  \n\nD. Starting long running task  \n   Long running task completed",
    "answer": "**Part 2 (Answer):**\n\nA. \n\nThe correct answer is A. When the `long_running_task` function is called, it starts a timer that ticks every second and prints \"Timer ticked at 1 seconds\". The `long_running_task` then proceeds to print its progress until completion. After the task completes, the timer stops ticking as its `running` attribute is set to `False`.\n\nThis demonstrates how an async decorator can be used to run additional logic (like a timer) alongside the main task, without blocking the execution of the main function.",
    "timestamp": "2025-04-26 11:52:17"
  },
  "q3_2025-04-26": {
    "question": "",
    "answer": "**Part 1 (Question):**\n\nConsider the following Python code snippet that uses a metaclass to create a singleton class:\n\n```python\nclass SingletonMeta(type):\n    _instances = {}\n\n    def __call__(cls, *args, **kwargs):\n        if cls not in cls._instances:\n            cls._instances[cls] = super().__call__(*args, **kwargs)\n        return cls._instances[cls]\n\nclass Database(metaclass=SingletonMeta):\n    def connect(self):\n        print(\"Connecting to the database...\")\n\n# Usage\ndb1 = Database()\ndb2 = Database()\n\nprint(db1 is db2)  # What will this print?\n```\n\nWhich of the following statements about this code is true?\n\nA) `db1` and `db2` are two separate instances of `Database`.\n\nB) When `db1.connect()` is called, it prints \"Connecting to the database...\" twice.\n\nC) The output of `print(db1 is db2)` will be `True`, indicating that `db1` and `db2` are the same instance.\n\nD) The metaclass implementation in `SingletonMeta` has a memory leak since it stores all instances indefinitely.\n\n**Part 2 (Answer):**\n\nC) The output of `print(db1 is db2)` will be `True`, indicating that `db1` and `db2` are the same instance.\n\n**Explanation:**\nIn Python, metaclasses control the creation process of a class. In this example, `SingletonMeta` overrides the `__call__` method to ensure that only one instance of `Database` is created. When you try to create multiple instances (`db1` and `db2`), the metaclass checks if an instance already exists for the class in question. If it does, it returns the existing instance instead of creating a new one. Therefore, `db1` and `db2` are indeed the same instance, making `print(db1 is db2)` evaluate to `True`. This demonstrates how a metaclass can be used to enforce singleton behavior in Python.",
    "timestamp": "2025-04-26 12:14:59"
  }
}